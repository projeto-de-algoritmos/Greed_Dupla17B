{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAA -  Greed \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PT 1. Codificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Estrutura inicial\n",
    "O primeiro passo é definir a estrutura da nossa heap, que será utilizada para guardar cada um dos nosso caracteres em conjunto com sua frequência de ocorrência e nós a esquerda e a direita na árvore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import os\n",
    "import filecmp\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HeapNode:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    #Funções para comparação entre nodes\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if(other == None):\n",
    "            return False\n",
    "        if(not isinstance(other, HeapNode)):\n",
    "            return False\n",
    "        return self.freq == other.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Arquivo a ser comprimido \n",
    "Agora podemos pedir ao usuário o caminho do arquivo a ser comprimido e ler seu conteúdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o caminho do arquivo:test.txt\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    original_path = input(\"Digite o caminho do arquivo:\")\n",
    "    if os.path.isfile(original_path):\n",
    "        break\n",
    "    print(\"Arquivo não encontrado, tente novamente.\")\n",
    "\n",
    "original_filename, original_file_extension = os.path.splitext(original_path)\n",
    "with open(original_path, 'r+') as file:\n",
    "    text = file.read()\n",
    "    text = text.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contagem de frequência \n",
    "\n",
    "Para executar o algoritmo de Huffman temos que primeiro contabilizar as frequências de ocorrência de cada caracter. Aqui fazemos isso e logo em seguida guardamos o resultado na nossa esturua de heap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, ' ': 9, 'm': 3, 'i': 5, 'r': 4, 'a': 15, 'l': 7, 'g': 3, 'u': 2, 'c': 1, 'o': 5, 's': 6, '\\n': 5, 't': 5, 'e': 6, 'd': 7, 'n': 2, 'j': 2, 'b': 1, 'f': 1, 'v': 1}\n"
     ]
    }
   ],
   "source": [
    "chars_frequency = {}\n",
    "for character in text:\n",
    "    if not character in chars_frequency:\n",
    "        chars_frequency[character] = 0\n",
    "    chars_frequency[character] += 1\n",
    "\n",
    "print(chars_frequency)\n",
    "\n",
    "heap = []\n",
    "\n",
    "for key in chars_frequency:\n",
    "    node = HeapNode(key, chars_frequency[key])\n",
    "    heapq.heappush(heap, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Codificação\n",
    "\n",
    "Agora construimos nossa árvore com os caracteres, de forma que os nós mais próximos da raiz são aqueles que representam os caracteres com maior frequência. Isso fica especialmente fácil por termos utilizado uma heap, já guardando os nós em ordem de frequência. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(len(heap)>1):\n",
    "    node1 = heapq.heappop(heap)\n",
    "    node2 = heapq.heappop(heap)\n",
    "\n",
    "    merged = HeapNode(None, node1.freq + node2.freq)\n",
    "    merged.left = node1\n",
    "    merged.right = node2\n",
    "\n",
    "    heapq.heappush(heap, merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estando com a árvore montada, podemos construir os códigos para cada caracter. Aqui fazemos isso recursivamente. \n",
    "\n",
    "\n",
    "Além disso, construimos também um outro dicionário, que chamamos de \"reverse_mapping\". Esse dicionário irá conter a correspondência CODIGO:CARACTER, os codigos sendo as chaves do dicionário. Fazemos isso porque mais tarde, na hora de descodificar uma string de bits, fica mais fácil achar o carácter que corresponde a um código com o dicionário dessa forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': '000000', 'c': '000001', 'f': '000010', 'v': '000011', 'n': '00010', 'j': '00011', ' ': '001', 'o': '0100', 'i': '0101', 't': '0110', '\\n': '0111', 'e': '1000', 's': '1001', 'm': '10100', 'b': '101010', 'u': '101011', 'g': '10110', 'r': '10111', 'd': '1100', 'l': '1101', 'a': '111'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reverse_mapping = {}\n",
    "codes = {}\n",
    "\n",
    "def build_huffman_code(root, current_code):\n",
    "    if(root == None):\n",
    "        return\n",
    "\n",
    "    if(root.char != None):\n",
    "        codes[root.char] = current_code\n",
    "        reverse_mapping[current_code] = root.char\n",
    "        return\n",
    "\n",
    "    build_huffman_code(root.left, current_code + \"0\") # Cada vez que vamos para esquerda, atribuimos mais um 0  \n",
    "    build_huffman_code(root.right, current_code + \"1\") # Cada vez que vamos para direita, atribuimos um 1\n",
    "    \n",
    "    \n",
    "build_huffman_code(heapq.heappop(heap), \"\")\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo os códigos para cada caracter, podemos juntar tudo e criar o código que representa o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000110100010110100010110111001111110110110101011101001110010000010100010110011110111011010001001011010000010110100010010110100000101111100010111110110010000010111110100110111111000111111100111011111001010111100100000111111011001111110111001111001110011101111111101100101101011101001010101111101000010010000111000001111100010101100100001011111010101000011101111000\n"
     ]
    }
   ],
   "source": [
    "encoded_text = \"\"\n",
    "for character in text:\n",
    "    encoded_text += codes[character]\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Construção dos bytes\n",
    "\n",
    "Se o numero de bits não for múltiplo de 8 temos que adicionar alguns bits extras. Isso porque na hora de ler o arquivo para decodifica-lo leremos os bytes do arquivo, não os bits, então utilizamos essa estratégia para não bagunçar os códigos de cada carácter na hora da leitura para descompressão.\n",
    "\n",
    "Após fazer isso, guardamos no inicio do novo codigo formado a informação de quantos bits extras existem, para que possamos desconsidera-los na hora da tradução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_padding = 8 - len(encoded_text) % 8\n",
    "for i in range(extra_padding):\n",
    "    encoded_text += \"0\"\n",
    "\n",
    "padded_info = \"{0:08b}\".format(extra_padding)\n",
    "encoded_text = padded_info + encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Armazenamento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_path=f'{original_filename}_compressed.bin'\n",
    "with open(compressed_path, 'wb') as output:\n",
    "\n",
    "    btarray = bytearray()\n",
    "    for i in range(0, len(encoded_text), 8):\n",
    "        byte = encoded_text[i:i+8]\n",
    "        btarray.append(int(byte, 2))        \n",
    "        \n",
    "    output.write(bytes(btarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, verificamos a eficiência da compressão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome do arquivo comprimido: lorem_compressed.bin\n",
      "Tamanho do arquivo original: 1427 bytes\n",
      "Tamanho do arquivo comprimido: 780 bytes\n",
      "O algoritmo conseguiu reduzir o tamanho do arquivo para 45.0% do seu tamanho original\n"
     ]
    }
   ],
   "source": [
    "original_file_size = os.path.getsize(original_path)\n",
    "compressed_file_size = os.path.getsize(compressed_path)\n",
    "size_reduction = format(round((((original_file_size-compressed_file_size)/original_file_size)*100), 0))\n",
    "print(f'Nome do arquivo comprimido: {compressed_path}')\n",
    "print(f'Tamanho do arquivo original: {original_file_size} bytes')\n",
    "print(f'Tamanho do arquivo comprimido: {compressed_file_size} bytes')\n",
    "print(f'O algoritmo conseguiu reduzir o tamanho do arquivo para {size_reduction}% do seu tamanho original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PT 2. Descodificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Leitura do arquivo \n",
    "O primeiro passo para iniciar uma descodificação é ler o arquivo binário que contem o conteúdo comprimido. Realizamos a leitura "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o caminho do arquivo a ser descomprimido: test.bin\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    compressed_path = input(\"Digite o caminho do arquivo a ser descomprimido: \")\n",
    "    if os.path.isfile(compressed_path):\n",
    "        break\n",
    "    print(\"Arquivo não encontrado, tente novamente.\")\n",
    "\n",
    "\n",
    "compressed_filename, compressed_file_extension = os.path.splitext(compressed_path)\n",
    "\n",
    "with open(compressed_path, 'rb') as file:\n",
    "    bits_string = \"\"\n",
    "\n",
    "    byte = file.read(1) # Leitura do primeiro byte\n",
    "    while(len(byte) > 0):\n",
    "        byte = ord(byte) # Conversão do byte para uma representação inteira\n",
    "        bits = bin(byte)[2:].rjust(8, '0') #Eliminamos o prefixo \"0b\" que precede os bits e convertemos o byte para uma string de bits\n",
    "        bits_string += bits\n",
    "        byte = file.read(1) # Leitura dos proximos bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remoção dos bits extras \n",
    "\n",
    "No passo de compressão adicionamos alguns bits extras ao código formado quando é o caso de o número de bits não ser multiplo de 8. Além disso, guardamos a informação de quantos bits extras existem logo no primeiro byte. Logo, agora basta lermos essa informação para sabermos quantos bits retirar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_info = bits_string[:8]\n",
    "extra_padding = int(padded_info, 2)\n",
    "\n",
    "bits_string = bits_string[8:] \n",
    "encoded_text = bits_string[:-1*extra_padding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tradução do código para texto \n",
    "\n",
    "Agora que temos a string com todos os bits do nosso conteúdo podemos realizar a tradução e obter o texto original. Para isso utilizamos o nosso dicionario \"reverse_mapping\", que foi construído tendo os códigos como chave e os caracteres como valor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_code = \"\"\n",
    "decompressed_text = \"\"\n",
    "\n",
    "for bit in encoded_text:\n",
    "    current_code += bit\n",
    "    if(current_code in reverse_mapping):\n",
    "        character = reverse_mapping[current_code]\n",
    "        decompressed_text += character\n",
    "        current_code = \"\"\n",
    "print(decompressed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Armazenamento \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompressed_file_path=f'{compressed_filename}_decompressed.txt'\n",
    "with open(decompressed_file_path, 'w') as output:\n",
    "    output.write(decompressed_text)\n",
    "print(f'O arquivo descompactado foi salvo como {decompressed_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PT 3. Teste\n",
    "\n",
    "Por fim, é possível comparar o arquivo original com o arquivo descomprimido para averiguar se os dois são de fato iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecmp.cmp(original_path, decompressed_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
